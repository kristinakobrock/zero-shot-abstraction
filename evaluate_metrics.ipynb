{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T13:45:44.903263Z",
     "start_time": "2025-01-25T13:45:43.037524Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils.analysis_from_interaction import *\n",
    "from egg.core.language_analysis import Disent\n",
    "from language_analysis_local import TopographicSimilarityConceptLevel, encode_target_concepts_for_topsim\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate metrics from stored interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T13:45:44.913235Z",
     "start_time": "2025-01-25T13:45:44.905968Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ('(3,4)', '(3,8)', '(3,16)', '(4,4)', '(4,8)', '(5,4)')\n",
    "n_attributes = (3, 3, 3, 4, 4, 5)\n",
    "n_values = (4, 8, 16, 4, 8, 4)\n",
    "epochs = 300\n",
    "n_runs = 5\n",
    "paths = ['results/' + d + '_game_size_10_vsf_3/' for d in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T07:49:46.066013Z",
     "start_time": "2025-01-27T07:49:46.059874Z"
    }
   },
   "outputs": [],
   "source": [
    "context_unaware = False # whether original or context_unaware simulations are evaluated\n",
    "zero_shot = True # whether zero-shot simulations are evaluated\n",
    "zero_shot_test = 'generic' # 'generic' or 'specific'\n",
    "test_interactions = True # whether scores should be calculated on test interactions (only with zero shot)\n",
    "zero_shot_test_ds = 'test_sampled_unscaled' # 'test' or 'test_fine' or 'test_sampled_unscaled'\n",
    "length_cost = False # whether length_cost was applied; length cost runs have been run with early stopping\n",
    "early_stopping = False # only with length cost\n",
    "rsa = False # only with context unaware\n",
    "rsa_test = 'train'\n",
    "setting = \"\"\n",
    "if length_cost:\n",
    "    setting = setting + 'length_cost/'\n",
    "    if not context_unaware:\n",
    "        setting = setting + 'context_aware'\n",
    "if context_unaware:\n",
    "    setting = setting + 'context_unaware'\n",
    "else:\n",
    "    if not length_cost:\n",
    "        setting = setting + 'standard'\n",
    "if zero_shot:\n",
    "    setting = setting + '/zero_shot/' + zero_shot_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T07:49:47.566124Z",
     "start_time": "2025-01-27T07:49:47.559145Z"
    }
   },
   "outputs": [],
   "source": [
    "# get n_epochs if early stopping\n",
    "if early_stopping:\n",
    "    \n",
    "    n_epochs_all_data = []\n",
    "    for d in range(len(datasets)):\n",
    "        \n",
    "        n_epochs = []\n",
    "        \n",
    "        for run in range(5):\n",
    "    \n",
    "            path_to_run = paths[d] + str(setting) +'/' + str(run) + '/' \n",
    "            with open(os.path.join(path_to_run, 'loss_and_metrics.pkl'), 'rb') as input_file:\n",
    "                data = pickle.load(input_file)\n",
    "                final_epoch = max(data['loss_train'].keys())\n",
    "                n_epochs.append(final_epoch)\n",
    "                \n",
    "        n_epochs_all_data.append(n_epochs)\n",
    "        \n",
    "else:\n",
    "    n_epochs_all_data = []\n",
    "    for d in range(len(datasets)):\n",
    "        n_epochs = []\n",
    "        \n",
    "        for run in range(5):\n",
    "            n_epochs.append(epochs)\n",
    "                \n",
    "        n_epochs_all_data.append(n_epochs)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entropy scores: MI, effectiveness, efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T11:34:28.976256Z",
     "start_time": "2024-10-09T11:34:26.569815Z"
    }
   },
   "outputs": [],
   "source": [
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    for run in range(5):\n",
    "\n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/' \n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "            else:\n",
    "                path_to_interaction = (path_to_run + 'interactions/' + zero_shot_test_ds + '/epoch_0/interaction_gpu0')\n",
    "        else:\n",
    "            path_to_rsa = (path_to_run + 'rsa/' + rsa_test + '/')\n",
    "            path_to_interaction = (path_to_rsa + 'rsa_' + rsa_test + '/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = information_scores(interaction, attributes, values, normalizer=\"arithmetic\")\n",
    "        \n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                pickle.dump(scores, open(path_to_run + 'entropy_scores.pkl', 'wb'))\n",
    "            else:\n",
    "                pickle.dump(scores, open(path_to_run + 'entropy_scores_' + zero_shot_test_ds + '.pkl', 'wb'))\n",
    "        else:\n",
    "            pickle.dump(scores, open(path_to_rsa + 'entropy_scores.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  message length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T11:32:26.669696Z",
     "start_time": "2024-10-09T11:32:07.718038Z"
    }
   },
   "outputs": [],
   "source": [
    "# we evaluated message length per hierarchy level after training but \n",
    "# you can also use the HierarchicalMessageLength callback and store the results \n",
    "\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    for run in range(5): \n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        if not rsa:\n",
    "            path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        else:\n",
    "            path_to_rsa = (path_to_run + 'rsa/' + rsa_test + '/')\n",
    "            path_to_interaction = (path_to_rsa + 'rsa_' + rsa_test + '/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "            \n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = message_length_per_hierarchy_level(interaction, attributes)\n",
    "        \n",
    "        if not rsa:\n",
    "            pickle.dump(scores, open(path_to_run + 'message_length_hierarchical.pkl', 'wb'))\n",
    "        else:\n",
    "            pickle.dump(scores, open(path_to_rsa + 'message_length_hierarchical.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  symbol redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T11:26:29.371582Z",
     "start_time": "2024-10-09T11:26:27.445228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    }
   ],
   "source": [
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    attributes = n_attributes[d]\n",
    "    values = n_values[d]\n",
    "    vs_factor = int(paths[d][-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "    vocab_size = 5\n",
    "    \n",
    "    for run in range(5): \n",
    "                \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "            else:\n",
    "                path_to_interaction = (path_to_run + 'interactions/' + zero_shot_test_ds + '/epoch_0/interaction_gpu0')\n",
    "        else:\n",
    "            path_to_rsa = (path_to_run + 'rsa/' + rsa_test + '/')\n",
    "            path_to_interaction = (path_to_rsa + 'rsa_' + rsa_test + '/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "        redundancy, MI = symbol_frequency(interaction, attributes, values, vocab_size)\n",
    "        \n",
    "        scores = {'symbol_redundancy': redundancy, 'MI_symbol-attribute_value': MI}\n",
    "        \n",
    "        if not rsa:\n",
    "            if not test_interactions:\n",
    "                pickle.dump(scores, open(path_to_run + 'symbol_redundancy.pkl', 'wb'))\n",
    "            else:\n",
    "                pickle.dump(scores, open(path_to_run + 'symbol_redundancy_' + zero_shot_test_ds + '.pkl', 'wb'))\n",
    "        else:\n",
    "            pickle.dump(scores, open(path_to_rsa + 'symbol_redundancy.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  compositionality scores: topsim, posdis, bosdis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-01-27T08:29:55.629963Z",
     "start_time": "2025-01-27T07:49:51.706425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset (3,4) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.40332517976907883, 'topsim_val': 0.41146580224416934}\n",
      "dataset (3,4) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.34933388253651915, 'topsim_val': 0.33915944380285873}\n",
      "dataset (3,4) run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.3359852197196985, 'topsim_val': 0.33274844260941827}\n",
      "dataset (3,4) run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.38024673020522165, 'topsim_val': 0.3893844503891836}\n",
      "dataset (3,4) run 4\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.333116421010744, 'topsim_val': 0.31919159864688673}\n",
      "dataset (3,8) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.2790530462319952, 'topsim_val': 0.29021895744304027}\n",
      "dataset (3,8) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.2936078546437526, 'topsim_val': 0.29891368110874283}\n",
      "dataset (3,8) run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.2599774455558579, 'topsim_val': 0.2565267224642263}\n",
      "dataset (3,8) run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.23488140815542483, 'topsim_val': 0.23643633677661333}\n",
      "dataset (3,8) run 4\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.2703790455095116, 'topsim_val': 0.25280734640960983}\n",
      "dataset (3,16) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.17019478605573157, 'topsim_val': 0.17446043988398952}\n",
      "dataset (3,16) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.1888175709436982, 'topsim_val': 0.2017047349694321}\n",
      "dataset (3,16) run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.2179449713171263, 'topsim_val': 0.2315951133434125}\n",
      "dataset (3,16) run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.17672666967095096, 'topsim_val': 0.18318690071644445}\n",
      "dataset (3,16) run 4\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.19758224426555593, 'topsim_val': 0.20482298420408712}\n",
      "dataset (4,4) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.31006977696321475, 'topsim_val': 0.32574265014881204}\n",
      "dataset (4,4) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.3815223936213001, 'topsim_val': 0.3798552377798022}\n",
      "dataset (4,4) run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.46433860725483467, 'topsim_val': 0.48241580307967097}\n",
      "dataset (4,4) run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.48202910485027245, 'topsim_val': 0.4883434482110529}\n",
      "dataset (4,4) run 4\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.4600058851085151, 'topsim_val': 0.47580409326513823}\n",
      "dataset (4,8) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.3218976177269033, 'topsim_val': 0.2974960422876485}\n",
      "dataset (4,8) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.309396960625128, 'topsim_val': 0.3092874432889463}\n",
      "dataset (4,8) run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.41274432415659823, 'topsim_val': 0.4379291544430416}\n",
      "dataset (4,8) run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.31402714366895595, 'topsim_val': 0.28984375596117834}\n",
      "dataset (4,8) run 4\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.29855354801051665, 'topsim_val': 0.30059325074498583}\n",
      "dataset (5,4) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.39384984991652155, 'topsim_val': 0.39802086071038795}\n",
      "dataset (5,4) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.41702244487226797, 'topsim_val': 0.3839957741065775}\n",
      "dataset (5,4) run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.5009589628471028, 'topsim_val': 0.4757756329471366}\n",
      "dataset (5,4) run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.523322360704807, 'topsim_val': 0.47427379509211837}\n",
      "dataset (5,4) run 4\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.3581298274653708, 'topsim_val': 0.3691247389364229}\n"
     ]
    }
   ],
   "source": [
    "# topsim for train and validation\n",
    "# although topsim values are stored throughout training if callbacks are verbose, we reevaluate the\n",
    "# final topsim scores with more data points \n",
    "# not yet implemented for rsa\n",
    "\n",
    "samples = 1000 # maybe shuffle from these because otherwise I just take the first 5,000 (which might not be the best)\n",
    "for d, dataset in enumerate(datasets):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    dim = [n_values[d]]*n_attributes[d]\n",
    "    \n",
    "    for run in range(5):\n",
    "        print(\"dataset\", dataset, \"run\", run)\n",
    "        \n",
    "        topsim_final = {}\n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        path_to_interaction_val = (path_to_run + 'interactions/validation/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        \n",
    "        TOPSIM = TopographicSimilarityConceptLevel(dim, is_gumbel=True)\n",
    "        \n",
    "        for mode in ['train', 'val']:\n",
    "\n",
    "            if mode == 'train':\n",
    "                interaction = torch.load(path_to_interaction_train)\n",
    "            elif mode == 'val':\n",
    "                interaction = torch.load(path_to_interaction_val)\n",
    "                  \n",
    "            messages = interaction.message.argmax(dim=-1)\n",
    "            sender_input = interaction.sender_input\n",
    "            n_targets = int(sender_input.shape[1]/2)\n",
    "            # get target objects and fixed vectors to re-construct concepts\n",
    "            target_objects = sender_input[:, :n_targets]\n",
    "            target_objects = k_hot_to_attributes(target_objects, n_values[d])\n",
    "            # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "            (objects, fixed) = retrieve_concepts_sampling(target_objects)\n",
    "            # add one such that zero becomes an empty attribute for the calculation (_)\n",
    "            objects = objects + 1\n",
    "            concepts = torch.from_numpy(objects * (np.array(fixed)))\n",
    "            specific_idx = np.where(np.sum(fixed, axis=1)==n_attributes[d])[0]\n",
    "            messages_specific = messages[specific_idx]\n",
    "            concepts_specific = concepts[specific_idx]\n",
    "            \n",
    "            generic_idx = np.where(np.sum(fixed, axis=1)==1)[0]\n",
    "            messages_generic = messages[generic_idx]\n",
    "            concepts_generic = concepts[generic_idx]\n",
    "\n",
    "            messages = [msg.tolist() for msg in messages]\n",
    "            messages_specific = [msg.tolist() for msg in messages_specific]\n",
    "            messages_generic = [msg.tolist() for msg in messages_generic]\n",
    "\n",
    "            encoded_input = encode_target_concepts_for_topsim(sender_input)\n",
    "\n",
    "            topsim = TOPSIM.compute_topsim(encoded_input[0:samples], messages[0:samples], meaning_distance_fn=\"hausdorff\", message_distance_fn=\"edit\") \n",
    "            \n",
    "            if not zero_shot:\n",
    "                topsim_specific = TOPSIM.compute_topsim(concepts_specific[0:samples], messages_specific[0:samples], \n",
    "                                                            meaning_distance_fn=\"hausdorff\", message_distance_fn=\"edit\")\n",
    "                \n",
    "                topsim_generic = TOPSIM.compute_topsim(concepts_generic[0:samples], messages_generic[0:samples],\n",
    "                                                       meaning_distance_fn=\"hausdorff\", message_distance_fn=\"edit\")\n",
    "\n",
    "            print('... topsim computed')\n",
    "\n",
    "            topsim_final['topsim_' + mode] = topsim\n",
    "            if not zero_shot:\n",
    "                topsim_final['topsim_specific_' + mode] = topsim_specific\n",
    "                topsim_final['topsim_generic_' + mode] = topsim_generic\n",
    "        \n",
    "        pickle.dump(topsim_final, open(path_to_run +  \"topsim_final_hd.pkl\", \"wb\" ) )\n",
    "        print(topsim_final)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T08:29:56.477579Z",
     "start_time": "2025-01-27T08:29:55.544367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset (3,4) run 0\n",
      "... topsim computed\n",
      "{'topsim_test': 0.05634361698190111}\n",
      "dataset (3,4) run 1\n",
      "... topsim computed\n",
      "{'topsim_test': -0.10788981249502495}\n",
      "dataset (3,4) run 2\n",
      "... topsim computed\n",
      "{'topsim_test': 0.2744622419018539}\n",
      "dataset (3,4) run 3\n",
      "... topsim computed\n",
      "{'topsim_test': -0.14238178946711544}\n",
      "dataset (3,4) run 4\n",
      "... topsim computed\n",
      "{'topsim_test': 0.007134754069184705}\n",
      "dataset (3,8) run 0\n",
      "... topsim computed\n",
      "{'topsim_test': -0.12436050990776149}\n",
      "dataset (3,8) run 1\n",
      "... topsim computed\n",
      "{'topsim_test': -0.006207359205640676}\n",
      "dataset (3,8) run 2\n",
      "... topsim computed\n",
      "{'topsim_test': 0.020330664549969273}\n",
      "dataset (3,8) run 3\n",
      "... topsim computed\n",
      "{'topsim_test': -0.043462069817788045}\n",
      "dataset (3,8) run 4\n",
      "... topsim computed\n",
      "{'topsim_test': -0.04048630273358914}\n",
      "dataset (3,16) run 0\n",
      "... topsim computed\n",
      "{'topsim_test': -0.09181309246672135}\n",
      "dataset (3,16) run 1\n",
      "... topsim computed\n",
      "{'topsim_test': -0.037759866357645895}\n",
      "dataset (3,16) run 2\n",
      "... topsim computed\n",
      "{'topsim_test': -0.04492781156783976}\n",
      "dataset (3,16) run 3\n",
      "... topsim computed\n",
      "{'topsim_test': -0.08634579244319537}\n",
      "dataset (3,16) run 4\n",
      "... topsim computed\n",
      "{'topsim_test': 0.008936239877154636}\n",
      "dataset (4,4) run 0\n",
      "... topsim computed\n",
      "{'topsim_test': 0.15650151533490733}\n",
      "dataset (4,4) run 1\n",
      "... topsim computed\n",
      "{'topsim_test': -0.04356027003166771}\n",
      "dataset (4,4) run 2\n",
      "... topsim computed\n",
      "{'topsim_test': 0.0889169761390553}\n",
      "dataset (4,4) run 3\n",
      "... topsim computed\n",
      "{'topsim_test': -0.07034729786105835}\n",
      "dataset (4,4) run 4\n",
      "... topsim computed\n",
      "{'topsim_test': -0.05102819812199713}\n",
      "dataset (4,8) run 0\n",
      "... topsim computed\n",
      "{'topsim_test': -0.08128507528753053}\n",
      "dataset (4,8) run 1\n",
      "... topsim computed\n",
      "{'topsim_test': 0.0822087027135667}\n",
      "dataset (4,8) run 2\n",
      "... topsim computed\n",
      "{'topsim_test': -0.023618430481805903}\n",
      "dataset (4,8) run 3\n",
      "... topsim computed\n",
      "{'topsim_test': 0.02139902280721555}\n",
      "dataset (4,8) run 4\n",
      "... topsim computed\n",
      "{'topsim_test': 0.04016490286887401}\n",
      "dataset (5,4) run 0\n",
      "... topsim computed\n",
      "{'topsim_test': -0.003470976153575107}\n",
      "dataset (5,4) run 1\n",
      "... topsim computed\n",
      "{'topsim_test': 0.14891470632633835}\n",
      "dataset (5,4) run 2\n",
      "... topsim computed\n",
      "{'topsim_test': -0.060472283372260294}\n",
      "dataset (5,4) run 3\n",
      "... topsim computed\n",
      "{'topsim_test': -0.09963596673362046}\n",
      "dataset (5,4) run 4\n",
      "... topsim computed\n",
      "{'topsim_test': -0.05483993270481933}\n"
     ]
    }
   ],
   "source": [
    "# topsim for test interactions\n",
    "\n",
    "if test_interactions:\n",
    "\n",
    "    samples = 1000 \n",
    "    for d, dataset in enumerate(datasets):\n",
    "        \n",
    "        n_epochs = n_epochs_all_data[d]\n",
    "        \n",
    "        dim = [n_values[d]]*n_attributes[d]\n",
    "        \n",
    "        for run in range(5):\n",
    "            print(\"dataset\", dataset, \"run\", run)\n",
    "            \n",
    "            topsim_final = {}\n",
    "            path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "            mode = 'test'\n",
    "            path_to_interaction_test = (path_to_run + 'interactions/' + zero_shot_test_ds + '/epoch_0/interaction_gpu0')\n",
    "            \n",
    "            TOPSIM = TopographicSimilarityConceptLevel(dim, is_gumbel=True)\n",
    "            \n",
    "            interaction = torch.load(path_to_interaction_test)\n",
    "                      \n",
    "            messages = interaction.message.argmax(dim=-1)\n",
    "            sender_input = interaction.sender_input\n",
    "            n_targets = int(sender_input.shape[1]/2)\n",
    "            # get target objects and fixed vectors to re-construct concepts\n",
    "            target_objects = sender_input[:, :n_targets]\n",
    "            target_objects = k_hot_to_attributes(target_objects, n_values[d])\n",
    "            # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "            (objects, fixed) = retrieve_concepts_sampling(target_objects)\n",
    "            # add one such that zero becomes an empty attribute for the calculation (_)\n",
    "            objects = objects + 1\n",
    "            concepts = torch.from_numpy(objects * (np.array(fixed)))\n",
    "\n",
    "            messages = [msg.tolist() for msg in messages]\n",
    "\n",
    "            encoded_input = encode_target_concepts_for_topsim(sender_input)\n",
    "\n",
    "            topsim = TOPSIM.compute_topsim(encoded_input[0:samples], messages[0:samples], meaning_distance_fn=\"hausdorff\")  \n",
    "\n",
    "            print('... topsim computed')\n",
    "\n",
    "            topsim_final['topsim_' + mode] = topsim\n",
    "    \n",
    "            pickle.dump(topsim_final, open(path_to_run +  \"topsim_final_hd\" + zero_shot_test_ds + \".pkl\", \"wb\" ) )\n",
    "            print(topsim_final)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topsim over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-14T14:07:47.776462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset (3,4) run 0\n",
      "dataset (3,4) run 1\n",
      "dataset (3,4) run 2\n",
      "dataset (3,4) run 3\n",
      "dataset (3,4) run 4\n",
      "dataset (3,8) run 0\n",
      "dataset (3,8) run 1\n",
      "dataset (3,8) run 2\n",
      "dataset (3,8) run 3\n",
      "dataset (3,8) run 4\n",
      "dataset (3,16) run 0\n",
      "dataset (3,16) run 1\n"
     ]
    }
   ],
   "source": [
    "for d, dataset in enumerate(datasets):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    for run in range(5):\n",
    "        print(\"dataset\", dataset, \"run\", run)\n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        path_to_interaction_val = (path_to_run + 'interactions/validation/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        \n",
    "        for mode in ['train', 'val']:\n",
    "\n",
    "            if mode == 'train':\n",
    "                interaction = torch.load(path_to_interaction_train)\n",
    "            elif mode == 'val':\n",
    "                interaction = torch.load(path_to_interaction_val)\n",
    "\n",
    "        messages = interaction.message.argmax(dim=-1)\n",
    "        sender_input = interaction.sender_input\n",
    "        messages = [msg.tolist() for msg in messages]\n",
    "        encoded_input = encode_target_concepts_for_topsim(sender_input)\n",
    "        dim = [n_values[0]] * n_attributes[0]\n",
    "        TOPSIM = TopographicSimilarityConceptLevel(dim, is_gumbel=True)\n",
    "        \n",
    "        samples = 5000\n",
    "        num_batches = len(messages) // samples + (len(messages) % samples > 0)\n",
    "        topsim_over_time = []\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            messages_batch = messages[i * samples:(i + 1) * samples]\n",
    "            topsim = TOPSIM.compute_topsim(encoded_input[i * samples:(i + 1) * samples], messages_batch)\n",
    "            topsim_over_time.append(topsim)\n",
    "            \n",
    "        pickle.dump(topsim_over_time, open(path_to_run +  \"topsim_over_time.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posdis and Bosdis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T10:30:06.379320Z",
     "start_time": "2024-07-17T10:30:03.266482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set [4, 4, 4]\n",
      "{'posdis_specific': 0.0465710423886776, 'bosdis_specific': nan, 'posdis_generic': 0.0296615157276392, 'bosdis_generic': nan, 'posdis': 0.04189429059624672, 'bosdis': nan}\n",
      "{'posdis_specific': 0.10868732631206512, 'bosdis_specific': nan, 'posdis_generic': 0.05492260307073593, 'bosdis_generic': nan, 'posdis': 0.08238240331411362, 'bosdis': nan}\n",
      "{'posdis_specific': 0.12329412996768951, 'bosdis_specific': nan, 'posdis_generic': 0.034101225435733795, 'bosdis_generic': nan, 'posdis': 0.08410908281803131, 'bosdis': nan}\n",
      "{'posdis_specific': 0.038105349987745285, 'bosdis_specific': nan, 'posdis_generic': 0.03253865987062454, 'bosdis_generic': nan, 'posdis': 0.039102792739868164, 'bosdis': nan}\n",
      "{'posdis_specific': 0.08939934521913528, 'bosdis_specific': nan, 'posdis_generic': 0.05377557873725891, 'bosdis_generic': nan, 'posdis': 0.06353741884231567, 'bosdis': nan}\n"
     ]
    }
   ],
   "source": [
    "# use Disent callback from egg\n",
    "\n",
    "for d in range(len(datasets)): \n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    path = paths[d]\n",
    "    dim = [n_values[d]] * n_attributes[d]\n",
    "    n_features = n_attributes[d] * n_values[d]\n",
    "    vs_factor = int(path[-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "    \n",
    "    print(\"data set\", dim)\n",
    "    \n",
    "    for run in range(5):\n",
    "        \n",
    "        posdis_bosdis = {}\n",
    "    \n",
    "        path_to_run = paths[d] + '/' + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction_train)\n",
    "        \n",
    "        messages = interaction.message.argmax(dim=-1)\n",
    "        sender_input = interaction.sender_input\n",
    "        n_targets = int(sender_input.shape[1]/2)\n",
    "        # get target objects and fixed vectors to re-construct concepts\n",
    "        target_objects = sender_input[:, :n_targets]\n",
    "        target_objects = k_hot_to_attributes(target_objects, n_values[d])\n",
    "        # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "        (objects, fixed) = retrieve_concepts_sampling(target_objects)\n",
    "        # add one such that zero becomes an empty attribute for the calculation (_)\n",
    "        objects = objects + 1\n",
    "        concepts = torch.from_numpy(objects * (np.array(fixed)))\n",
    "\n",
    "        # concrete/specific concepts: where all attributes are fixed\n",
    "        concepts_specific = torch.tensor(\n",
    "            objects[torch.sum(torch.from_numpy(fixed), dim=1) == n_attributes[d]])\n",
    "        messages_specific = messages[torch.sum(torch.from_numpy(fixed), dim=1) == n_attributes[d]]\n",
    "\n",
    "        # generic concepts: where only one attribute is fixed\n",
    "        concepts_generic = torch.tensor(\n",
    "            objects[torch.sum(torch.from_numpy(fixed), dim=1) == 1])\n",
    "        messages_generic = messages[torch.sum(torch.from_numpy(fixed), dim=1) == 1]\n",
    "        \n",
    "        posdis_specific = Disent.posdis(concepts_specific, messages_specific)\n",
    "        bosdis_specific = Disent.bosdis(concepts_specific, messages_specific, vocab_size)\n",
    "\n",
    "        posdis_generic = Disent.posdis(concepts_generic, messages_generic)\n",
    "        bosdis_generic = Disent.bosdis(concepts_generic, messages_generic, vocab_size)\n",
    "        \n",
    "        posdis = Disent.posdis(torch.from_numpy(objects), messages)\n",
    "        bosdis = Disent.bosdis(torch.from_numpy(objects), messages, vocab_size)\n",
    "        \n",
    "        posdis_bosdis['posdis_specific'] = posdis_specific\n",
    "        posdis_bosdis['bosdis_specific'] = bosdis_specific\n",
    "        posdis_bosdis['posdis_generic'] = posdis_generic\n",
    "        posdis_bosdis['bosdis_generic'] = bosdis_generic\n",
    "        posdis_bosdis['posdis'] = posdis\n",
    "        posdis_bosdis['bosdis'] = bosdis\n",
    "\n",
    "        print(posdis_bosdis)\n",
    "    \n",
    "        pickle.dump(posdis_bosdis, open(path_to_run + \"posdis_bosdis.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posdis and bosdis concept x context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T10:30:06.480256Z",
     "start_time": "2024-07-17T10:30:06.366019Z"
    }
   },
   "outputs": [],
   "source": [
    "# bosdis concept x context\n",
    "from utils.analysis_from_interaction import bosdis\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "\n",
    "    vs_factor = int(paths[d][-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "    \n",
    "    for run in range(5):\n",
    "\n",
    "        path_to_run = paths[d] + '/' + str(setting) +'/' + str(run) + '/' \n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = bosdis(interaction, attributes, values, vocab_size)\n",
    "\n",
    "        pickle.dump(scores, open(path_to_run + 'bosdis_scores.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T10:30:09.900525Z",
     "start_time": "2024-07-17T10:30:06.484425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,4)_game_size_10_vsf_0//length_cost/context_unaware/0/\n",
      "results/(3,4)_game_size_10_vsf_0//length_cost/context_unaware/1/\n",
      "results/(3,4)_game_size_10_vsf_0//length_cost/context_unaware/2/\n",
      "results/(3,4)_game_size_10_vsf_0//length_cost/context_unaware/3/\n",
      "results/(3,4)_game_size_10_vsf_0//length_cost/context_unaware/4/\n"
     ]
    }
   ],
   "source": [
    "# posdis concept x context\n",
    "from utils.analysis_from_interaction import posdis\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "\n",
    "    vs_factor = int(paths[d][-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "\n",
    "    for run in range(5):\n",
    "        path_to_run = paths[d] + '/' + str(setting) + '/' + str(run) + '/'\n",
    "        print(path_to_run)\n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        #print(path_to_interaction)\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = posdis(interaction, attributes, values, vocab_size)\n",
    "\n",
    "        pickle.dump(scores, open(path_to_run + 'posdis_scores.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## co-occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not yet implemented:\n",
    "\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    vs_factor = int(paths[d][-2])\n",
    "    \n",
    "    for run in range(5): \n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        \n",
    "        scores = cooccurrence_per_hierarchy_level(interaction, attributes, values, vs_factor)\n",
    "\n",
    "        print(scores)\n",
    "        \n",
    "        pickle.dump(scores, open(path_to_run + 'normalized_cooccurrence.pkl', 'wb'))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "egg",
   "language": "python",
   "display_name": "egg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
